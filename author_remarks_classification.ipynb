{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6128726aa6d488e914f7cd0f752fd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5365871d43e24274be38a527642b6e7b",
              "IPY_MODEL_f44f6e4f31a34103ad191bebc5d849f3",
              "IPY_MODEL_f217d00cc4dc4053a20c7989cde2b102"
            ],
            "layout": "IPY_MODEL_2357868f7bfd42f6ad392de438c943b9"
          }
        },
        "5365871d43e24274be38a527642b6e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_209c67f65f654863a52258eb10cc7fba",
            "placeholder": "​",
            "style": "IPY_MODEL_8712c0c0f48f4b55b737f472c7eac58b",
            "value": "Downloading: 100%"
          }
        },
        "f44f6e4f31a34103ad191bebc5d849f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7767c02ad75d462480f8e65ec76fcbda",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_842c04af1ce04f14a22a9af821b74f6b",
            "value": 791656
          }
        },
        "f217d00cc4dc4053a20c7989cde2b102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd55ee840734418fac3990b1c736e397",
            "placeholder": "​",
            "style": "IPY_MODEL_2c060be2f1b746e6badc075f1db11075",
            "value": " 792k/792k [00:00&lt;00:00, 4.35MB/s]"
          }
        },
        "2357868f7bfd42f6ad392de438c943b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "209c67f65f654863a52258eb10cc7fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8712c0c0f48f4b55b737f472c7eac58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7767c02ad75d462480f8e65ec76fcbda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "842c04af1ce04f14a22a9af821b74f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd55ee840734418fac3990b1c736e397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c060be2f1b746e6badc075f1db11075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05fa81aa78444f57bda520affea7a2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd363a92ff4d422b975f9eac3816561c",
              "IPY_MODEL_0538865124f64e61b285fcf8512e5da0",
              "IPY_MODEL_448947ddc76344639461c4e7c55d5bc6"
            ],
            "layout": "IPY_MODEL_41ead10281144709b10214e36e7b0a67"
          }
        },
        "cd363a92ff4d422b975f9eac3816561c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6067a937cce440b092094423f6a7b5e1",
            "placeholder": "​",
            "style": "IPY_MODEL_009d70abbdbd432ba0c4e71831d7f4d9",
            "value": "Downloading: 100%"
          }
        },
        "0538865124f64e61b285fcf8512e5da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1641e16184314409a9682d1b70938690",
            "max": 1197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25cf737d9b444838bd146c8861a57471",
            "value": 1197
          }
        },
        "448947ddc76344639461c4e7c55d5bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09579da0b1446319c56c0c584e52aa4",
            "placeholder": "​",
            "style": "IPY_MODEL_3840376afabe43a4aee10ecf065751b2",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 16.2kB/s]"
          }
        },
        "41ead10281144709b10214e36e7b0a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6067a937cce440b092094423f6a7b5e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009d70abbdbd432ba0c4e71831d7f4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1641e16184314409a9682d1b70938690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25cf737d9b444838bd146c8861a57471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e09579da0b1446319c56c0c584e52aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3840376afabe43a4aee10ecf065751b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e73be978fff548fa89aefcf5cf8ceb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beec321493904785b716c5223fea0abb",
              "IPY_MODEL_70db1756527044afa0d2d995e787f6e9",
              "IPY_MODEL_bcf0b1dfe41f41fc9b2393608e05d2cb"
            ],
            "layout": "IPY_MODEL_3d724f1f79a94683b250d5ebc99789a0"
          }
        },
        "beec321493904785b716c5223fea0abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be0d017e26314437846105a8ac78a75a",
            "placeholder": "​",
            "style": "IPY_MODEL_7ee1c067c3be4bd587a454048fc1df92",
            "value": "Downloading: 100%"
          }
        },
        "70db1756527044afa0d2d995e787f6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e3313f8255247e883eb7dd4ed1dd9c4",
            "max": 242065649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d83cf857c8f044a8a51d60da4ff82ea8",
            "value": 242065649
          }
        },
        "bcf0b1dfe41f41fc9b2393608e05d2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe08b3a8a3946c4ad84052d26f241d5",
            "placeholder": "​",
            "style": "IPY_MODEL_c392ce4b65c04ddbb6af7cd8115a74f8",
            "value": " 242M/242M [00:04&lt;00:00, 61.8MB/s]"
          }
        },
        "3d724f1f79a94683b250d5ebc99789a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0d017e26314437846105a8ac78a75a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ee1c067c3be4bd587a454048fc1df92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e3313f8255247e883eb7dd4ed1dd9c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d83cf857c8f044a8a51d60da4ff82ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fe08b3a8a3946c4ad84052d26f241d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c392ce4b65c04ddbb6af7cd8115a74f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Тетрадка с моделью классификации"
      ],
      "metadata": {
        "id": "fuZwNzScO78z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPxIibU9HPJM",
        "outputId": "2245a5c1-4ae4-4df3-a1b8-bed04f836423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9AuGWq0IDuq",
        "outputId": "05901a02-e6c8-4b79-b666-8a342e13c337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 27.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCnuZE90IQbI",
        "outputId": "002a9b2b-5a1d-41ed-9a99-9b26d4e49f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.2-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 30.1 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 60.0 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 70.5 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=828b5aa6116ba7da8954cde5556b4c844745a658a22665490be70b8fca58dcbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.3 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.2 pbr-5.10.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentencepiece==0.1.91"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U__ZghyYdIb",
        "outputId": "f795180a-5974-4c05-d991-1bc46c40876f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 29.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import optuna\n",
        "from optuna.pruners import SuccessiveHalvingPruner\n",
        "from optuna.samplers import TPESampler"
      ],
      "metadata": {
        "id": "zfPNdEhzHhdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.amp.autocast(enabled=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6XA-QjkICSV",
        "outputId": "8195eed5-e7dd-4850-d63d-67002045c268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.cuda.amp.autocast_mode.autocast at 0x7fdd1fe85ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed to get reproducible results\n",
        "\n",
        "SEED = 15\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zTNbqBnIZq6",
        "outputId": "e342da95-f1bf-4246-dcb4-bd1b958efaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fdcb2d7cc10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# tell pytorch to use cuda\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "_-pdkIhXIcTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data"
      ],
      "metadata": {
        "id": "AcTCDJgiPD-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/kursovaya2022/1000_entries.csv')"
      ],
      "metadata": {
        "id": "MgJ0gYDtIeAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EuFB7_IOItSd",
        "outputId": "c215eb23-ca79-44af-8c74-016eb354bcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                               text  \\\n",
              "0             0  Разве мог Александр Мелявский, ступая на перро...   \n",
              "1             2  Разве мог Александр Мелявский, ступая на перро...   \n",
              "2             3  Разве мог Александр Мелявский, ступая на перро...   \n",
              "3             4  Разве мог Александр Мелявский, ступая на перро...   \n",
              "4             5  Разве мог Александр Мелявский, ступая на перро...   \n",
              "..          ...                                                ...   \n",
              "995        1039  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "996        1040  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "997        1041  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "998        1042  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "999        1043  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "\n",
              "                                            clean_text  \\\n",
              "0    Разве мог Александр Мелявский, ступая на перро...   \n",
              "1    Разве мог Александр Мелявский, ступая на перро...   \n",
              "2    Разве мог Александр Мелявский, ступая на перро...   \n",
              "3    Разве мог Александр Мелявский, ступая на перро...   \n",
              "4    Разве мог Александр Мелявский, ступая на перро...   \n",
              "..                                                 ...   \n",
              "995  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "996  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "997  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "998  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "999  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "\n",
              "                                         direct_speech  \\\n",
              "0    <said aloud='True' type='direct'>-Ребята, дава...   \n",
              "1    <said aloud='True' type='direct'>- Он здесь</s...   \n",
              "2    <said aloud='True' type='direct'>- Катенька ид...   \n",
              "3    <said aloud='True' type='direct'>- Катенька ид...   \n",
              "4    <said aloud='True' type='direct'>- Катенька ид...   \n",
              "..                                                 ...   \n",
              "995  <said aloud='True' type='direct'>- А закусываю...   \n",
              "996  <said aloud='True' type='direct'>- Оставь меня...   \n",
              "997  <said aloud='True' type='direct'>- Советские л...   \n",
              "998  <said aloud='True' type='direct'>- Нет, выше б...   \n",
              "999  <said aloud='True' type='direct'>- Дмитрий Ана...   \n",
              "\n",
              "                                   clean_direct_speech  \\\n",
              "0    -Ребята, давайте сходим в воскресенье на стади...   \n",
              "1    - Он здесь! - Сказал Александр, подойдя к Миха...   \n",
              "2    - Катенька иди, мы сами справимся. - Сказала о...   \n",
              "3    - Катенька иди, мы сами справимся. - Сказала о...   \n",
              "4    - Катенька иди, мы сами справимся. - Сказала о...   \n",
              "..                                                 ...   \n",
              "995  - А закусываю только после двух подряд! -- гор...   \n",
              "996  - Оставь меня старушка, я в астрале! Хочу -- р...   \n",
              "997  - Советские люди не могут продать Родину и в И...   \n",
              "998  - Нет, выше бери, - сказал Жорж и показал квер...   \n",
              "999  - Дмитрий Анатольевич я, - обиженно сказал гос...   \n",
              "\n",
              "                               direct_speech_wo_author  \\\n",
              "0     -Ребята, давайте сходим в воскресенье на стадион   \n",
              "1                                           - Он здесь   \n",
              "2                    - Катенька иди, мы сами справимся   \n",
              "3                                                 . -    \n",
              "4    поддержала её, вторая женщина. -Я подожду на у...   \n",
              "..                                                 ...   \n",
              "995             - А закусываю только после двух подряд   \n",
              "996  - Оставь меня старушка, я в астрале! Хочу -- р...   \n",
              "997  - Советские люди не могут продать Родину и в И...   \n",
              "998                                   - Нет, выше бери   \n",
              "999                            - Дмитрий Анатольевич я   \n",
              "\n",
              "                                         author_remark  \\\n",
              "0    <speech_verb semantic=\"speech\" emotion=\"neutra...   \n",
              "1    <speech_verb semantic=\"speech\" emotion=\"neutra...   \n",
              "2    <speech_verb semantic=\"speech\" emotion=\"neutra...   \n",
              "3                                                 , -    \n",
              "4    <speech_verb semantic=\"speech\" emotion=\"neutra...   \n",
              "..                                                 ...   \n",
              "995  гордо <speech_verb semantic=\"speech\" emotion=\"...   \n",
              "996  <speech_verb semantic=\"speech\" emotion=\"neutra...   \n",
              "997  гордо <speech_verb semantic=\"speech\" emotion=\"...   \n",
              "998  <speech_verb semantic=\"speech\" emotion=\"neutra...   \n",
              "999  обиженно <speech_verb semantic=\"speech\" emotio...   \n",
              "\n",
              "                                   clean_author_remark     verb  \\\n",
              "0    сказала Таня, когда парни подошли к девочкам, ...  сказала   \n",
              "1           Сказал Александр, подойдя к Михал Иванычу.   сказал   \n",
              "2    Сказала одна из женщин, избавив парня, от нело...  сказала   \n",
              "3                                                 , -   вопроса   \n",
              "4    сказал Саша, закрывая дверь кабинета, и обрадо...   сказал   \n",
              "..                                                 ...      ...   \n",
              "995   гордо ответил Владимир и хряпнул второй стопарь.  ответил   \n",
              "996  сказал ей Владимир Владимирович и вернулся в к...   сказал   \n",
              "997  гордо сказал Бунша и тут же осекся. На полу шк...   сказал   \n",
              "998   сказал Жорж и показал кверху указательный палец.   сказал   \n",
              "999             обиженно сказал гость и потупил глаза.   сказал   \n",
              "\n",
              "                                           masked_text  \\\n",
              "0    Разве мог Александр Мелявский, ступая на перро...   \n",
              "1    Разве мог Александр Мелявский, ступая на перро...   \n",
              "2    Разве мог Александр Мелявский, ступая на перро...   \n",
              "3    Разве мог Александр Мелявский, ступая на перро...   \n",
              "4    Разве мог Александр Мелявский, ступая на перро...   \n",
              "..                                                 ...   \n",
              "995  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "996  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "997  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "998  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "999  (фарс-пародия к/ф «Иван Васильевич меняет проф...   \n",
              "\n",
              "                                              maske_ds verb_lemma  \n",
              "0    -Ребята, давайте сходим в воскресенье на стади...    сказать  \n",
              "1    - Он здесь! - [MASK] Александр, подойдя к Миха...    сказать  \n",
              "2    - Катенька иди, мы сами справимся. - [MASK] од...    сказать  \n",
              "3    - Катенька иди, мы сами справимся. - [MASK] од...     вопрос  \n",
              "4    - Катенька иди, мы сами справимся. - [MASK] од...    сказать  \n",
              "..                                                 ...        ...  \n",
              "995  - А закусываю только после двух подряд! -- гор...   ответить  \n",
              "996  - Оставь меня старушка, я в астрале! Хочу -- р...    сказать  \n",
              "997  - Советские люди не могут продать Родину и в И...    сказать  \n",
              "998  - Нет, выше бери, - [MASK] Жорж и показал квер...    сказать  \n",
              "999  - Дмитрий Анатольевич я, - обиженно [MASK] гос...    сказать  \n",
              "\n",
              "[1000 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc543832-3b7b-44f3-a813-f376ba45e09d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>direct_speech</th>\n",
              "      <th>clean_direct_speech</th>\n",
              "      <th>direct_speech_wo_author</th>\n",
              "      <th>author_remark</th>\n",
              "      <th>clean_author_remark</th>\n",
              "      <th>verb</th>\n",
              "      <th>masked_text</th>\n",
              "      <th>maske_ds</th>\n",
              "      <th>verb_lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;-Ребята, дава...</td>\n",
              "      <td>-Ребята, давайте сходим в воскресенье на стади...</td>\n",
              "      <td>-Ребята, давайте сходим в воскресенье на стадион</td>\n",
              "      <td>&lt;speech_verb semantic=\"speech\" emotion=\"neutra...</td>\n",
              "      <td>сказала Таня, когда парни подошли к девочкам, ...</td>\n",
              "      <td>сказала</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>-Ребята, давайте сходим в воскресенье на стади...</td>\n",
              "      <td>сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- Он здесь&lt;/s...</td>\n",
              "      <td>- Он здесь! - Сказал Александр, подойдя к Миха...</td>\n",
              "      <td>- Он здесь</td>\n",
              "      <td>&lt;speech_verb semantic=\"speech\" emotion=\"neutra...</td>\n",
              "      <td>Сказал Александр, подойдя к Михал Иванычу.</td>\n",
              "      <td>сказал</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>- Он здесь! - [MASK] Александр, подойдя к Миха...</td>\n",
              "      <td>сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- Катенька ид...</td>\n",
              "      <td>- Катенька иди, мы сами справимся. - Сказала о...</td>\n",
              "      <td>- Катенька иди, мы сами справимся</td>\n",
              "      <td>&lt;speech_verb semantic=\"speech\" emotion=\"neutra...</td>\n",
              "      <td>Сказала одна из женщин, избавив парня, от нело...</td>\n",
              "      <td>сказала</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>- Катенька иди, мы сами справимся. - [MASK] од...</td>\n",
              "      <td>сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- Катенька ид...</td>\n",
              "      <td>- Катенька иди, мы сами справимся. - Сказала о...</td>\n",
              "      <td>. -</td>\n",
              "      <td>, -</td>\n",
              "      <td>, -</td>\n",
              "      <td>вопроса</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>- Катенька иди, мы сами справимся. - [MASK] од...</td>\n",
              "      <td>вопрос</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- Катенька ид...</td>\n",
              "      <td>- Катенька иди, мы сами справимся. - Сказала о...</td>\n",
              "      <td>поддержала её, вторая женщина. -Я подожду на у...</td>\n",
              "      <td>&lt;speech_verb semantic=\"speech\" emotion=\"neutra...</td>\n",
              "      <td>сказал Саша, закрывая дверь кабинета, и обрадо...</td>\n",
              "      <td>сказал</td>\n",
              "      <td>Разве мог Александр Мелявский, ступая на перро...</td>\n",
              "      <td>- Катенька иди, мы сами справимся. - [MASK] од...</td>\n",
              "      <td>сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1039</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- А закусываю...</td>\n",
              "      <td>- А закусываю только после двух подряд! -- гор...</td>\n",
              "      <td>- А закусываю только после двух подряд</td>\n",
              "      <td>гордо &lt;speech_verb semantic=\"speech\" emotion=\"...</td>\n",
              "      <td>гордо ответил Владимир и хряпнул второй стопарь.</td>\n",
              "      <td>ответил</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>- А закусываю только после двух подряд! -- гор...</td>\n",
              "      <td>ответить</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1040</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- Оставь меня...</td>\n",
              "      <td>- Оставь меня старушка, я в астрале! Хочу -- р...</td>\n",
              "      <td>- Оставь меня старушка, я в астрале! Хочу -- р...</td>\n",
              "      <td>&lt;speech_verb semantic=\"speech\" emotion=\"neutra...</td>\n",
              "      <td>сказал ей Владимир Владимирович и вернулся в к...</td>\n",
              "      <td>сказал</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>- Оставь меня старушка, я в астрале! Хочу -- р...</td>\n",
              "      <td>сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1041</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- Советские л...</td>\n",
              "      <td>- Советские люди не могут продать Родину и в И...</td>\n",
              "      <td>- Советские люди не могут продать Родину и в И...</td>\n",
              "      <td>гордо &lt;speech_verb semantic=\"speech\" emotion=\"...</td>\n",
              "      <td>гордо сказал Бунша и тут же осекся. На полу шк...</td>\n",
              "      <td>сказал</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>- Советские люди не могут продать Родину и в И...</td>\n",
              "      <td>сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1042</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- Нет, выше б...</td>\n",
              "      <td>- Нет, выше бери, - сказал Жорж и показал квер...</td>\n",
              "      <td>- Нет, выше бери</td>\n",
              "      <td>&lt;speech_verb semantic=\"speech\" emotion=\"neutra...</td>\n",
              "      <td>сказал Жорж и показал кверху указательный палец.</td>\n",
              "      <td>сказал</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>- Нет, выше бери, - [MASK] Жорж и показал квер...</td>\n",
              "      <td>сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1043</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>&lt;said aloud='True' type='direct'&gt;- Дмитрий Ана...</td>\n",
              "      <td>- Дмитрий Анатольевич я, - обиженно сказал гос...</td>\n",
              "      <td>- Дмитрий Анатольевич я</td>\n",
              "      <td>обиженно &lt;speech_verb semantic=\"speech\" emotio...</td>\n",
              "      <td>обиженно сказал гость и потупил глаза.</td>\n",
              "      <td>сказал</td>\n",
              "      <td>(фарс-пародия к/ф «Иван Васильевич меняет проф...</td>\n",
              "      <td>- Дмитрий Анатольевич я, - обиженно [MASK] гос...</td>\n",
              "      <td>сказать</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc543832-3b7b-44f3-a813-f376ba45e09d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc543832-3b7b-44f3-a813-f376ba45e09d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc543832-3b7b-44f3-a813-f376ba45e09d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initiate tokenizer"
      ],
      "metadata": {
        "id": "V9iKDcCqPGX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate T5 tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "# check token ids\n",
        "tokenizer.eos_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "d6128726aa6d488e914f7cd0f752fd5a",
            "5365871d43e24274be38a527642b6e7b",
            "f44f6e4f31a34103ad191bebc5d849f3",
            "f217d00cc4dc4053a20c7989cde2b102",
            "2357868f7bfd42f6ad392de438c943b9",
            "209c67f65f654863a52258eb10cc7fba",
            "8712c0c0f48f4b55b737f472c7eac58b",
            "7767c02ad75d462480f8e65ec76fcbda",
            "842c04af1ce04f14a22a9af821b74f6b",
            "fd55ee840734418fac3990b1c736e397",
            "2c060be2f1b746e6badc075f1db11075",
            "05fa81aa78444f57bda520affea7a2d2",
            "cd363a92ff4d422b975f9eac3816561c",
            "0538865124f64e61b285fcf8512e5da0",
            "448947ddc76344639461c4e7c55d5bc6",
            "41ead10281144709b10214e36e7b0a67",
            "6067a937cce440b092094423f6a7b5e1",
            "009d70abbdbd432ba0c4e71831d7f4d9",
            "1641e16184314409a9682d1b70938690",
            "25cf737d9b444838bd146c8861a57471",
            "e09579da0b1446319c56c0c584e52aa4",
            "3840376afabe43a4aee10ecf065751b2"
          ]
        },
        "id": "sQ-w5CKNYF-i",
        "outputId": "2b5cef00-a6df-4872-e7d3-05d7c640d1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6128726aa6d488e914f7cd0f752fd5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05fa81aa78444f57bda520affea7a2d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.bos_token_id\n",
        "tokenizer.unk_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsFaNhJzZrl-",
        "outputId": "179c325f-3497-4e82-baeb-193d71451866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tc6Dvl6ZvPV",
        "outputId": "9ad8c68c-b6ab-4d31-9d75-8870d9365bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new df for training"
      ],
      "metadata": {
        "id": "neY6LaN5PJHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_class = df[['maske_ds', 'verb_lemma']]"
      ],
      "metadata": {
        "id": "1HvADxWqZ23M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_corpus(df, tokenizer, max_len):\n",
        "    # token ID storage\n",
        "    input_ids = []\n",
        "    # attension mask storage\n",
        "    attention_masks = []\n",
        "    # max len -- 512 is max\n",
        "    max_len = max_len\n",
        "    # for every document:\n",
        "    for doc in df:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            doc,  # document to encode.\n",
        "                            add_special_tokens=True,  # add tokens relative to model\n",
        "                            max_length=max_len,  # set max length\n",
        "                            truncation=True,  # truncate longer messages\n",
        "                            pad_to_max_length=True,  # add padding\n",
        "                            return_attention_mask=True,  # create attn. masks\n",
        "                            return_tensors='pt'  # return pytorch tensors\n",
        "                       )\n",
        "\n",
        "        # add the tokenized sentence to the list\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # and its attention mask (differentiates padding from non-padding)\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# create tokenized data\n",
        "body_input_ids, body_attention_masks = tokenize_corpus(df_class['maske_ds'].values, tokenizer, 512)\n",
        "\n",
        "\n",
        "\n",
        "# how long are tokenized targets\n",
        "ls = []\n",
        "for i in range(df_class.shape[0]):\n",
        "    ls.append(len(tokenizer.tokenize(df_class.iloc[i]['verb_lemma'])))\n",
        "\n",
        "temp_df = pd.DataFrame({'len_tokens': ls})\n",
        "temp_df['len_tokens'].mean()  # 2.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sNj-YeIZw6O",
        "outputId": "6e86a9ab-9b4a-4b86-869c-196181498233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.973"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['len_tokens'].median()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_45Hx5zrai_i",
        "outputId": "f4c02670-8da5-43ec-cc6f-22d9d2b8ac51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df['len_tokens'].max() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JmTY9X4apEz",
        "outputId": "751bbd85-4efd-41d0-eeb0-838d13515cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_input_ids, target_attention_masks = tokenize_corpus(df_class['maske_ds'].values, tokenizer, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoO0A2uParSf",
        "outputId": "b3d999c6-1489-4b99-99bb-704342bffa1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(body_tokens, body_masks, target_token, target_masks):\n",
        "    # create tensor data sets\n",
        "    tensor_df = TensorDataset(body_tokens, body_masks, target_token, target_masks)\n",
        "    # 80% of df\n",
        "    train_size = int(0.8 * len(df_class))\n",
        "    # 20% of df\n",
        "    val_size = len(df_class) - train_size\n",
        "    # 50% of validation\n",
        "    test_size = int(val_size - 0.5*val_size)\n",
        "    # divide the dataset by randomly selecting samples\n",
        "    train_dataset, val_dataset = random_split(tensor_df, [train_size, val_size])\n",
        "    # divide validation by randomly selecting samples\n",
        "    val_dataset, test_dataset = random_split(val_dataset, [test_size, len(val_dataset) - test_size])\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "# create tensor data sets\n",
        "train_dataset, val_dataset, test_dataset = prepare_dataset(body_input_ids,\n",
        "                                                           body_attention_masks,\n",
        "                                                           target_input_ids,\n",
        "                                                           target_attention_masks\n",
        "                                                           )"
      ],
      "metadata": {
        "id": "AIdaFYfeawaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer):\n",
        "\n",
        "    # capture time\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # reset total loss for epoch\n",
        "    train_total_loss = 0\n",
        "    total_train_f1 = 0\n",
        "\n",
        "    # put model into traning mode\n",
        "    model.train()\n",
        "\n",
        "    # for each batch of training data...\n",
        "    for step, batch in enumerate(dataloader):\n",
        "\n",
        "        # progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(dataloader)))\n",
        "\n",
        "        # Unpack this training batch from our dataloader:\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input tokens\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: target tokens\n",
        "        #   [3]: target attenion masks\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_input_mask = batch[1].cuda()\n",
        "        b_target_ids = batch[2].cuda()\n",
        "        b_target_mask = batch[3].cuda()\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # runs the forward pass with autocasting.\n",
        "        with autocast():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids,\n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_target_ids,\n",
        "                            decoder_attention_mask=b_target_mask)\n",
        "\n",
        "            loss, prediction_scores = outputs[:2]\n",
        "\n",
        "            # sum the training loss over all batches for average loss at end\n",
        "            # loss is a tensor containing a single value\n",
        "            train_total_loss += loss.item()\n",
        "\n",
        "        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "        # Backward passes under autocast are not recommended.\n",
        "        # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
        "        # otherwise, optimizer.step() is skipped.\n",
        "        scaler.step(optimizer)\n",
        "\n",
        "        # Updates the scale for next iteration.\n",
        "        scaler.update()\n",
        "\n",
        "        # update the learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # calculate the average loss over all of the batches\n",
        "    avg_train_loss = train_total_loss / len(dataloader)\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'Train Loss': avg_train_loss\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # training time end\n",
        "    training_time = format_time(time.time() - total_t0)\n",
        "\n",
        "    # print result summaries\n",
        "    print(\"\")\n",
        "    print(\"summary results\")\n",
        "    print(\"epoch | trn loss | trn time \")\n",
        "    print(f\"{epoch+1:5d} | {avg_train_loss:.5f} | {training_time:}\")\n",
        "\n",
        "    return training_stats"
      ],
      "metadata": {
        "id": "2B2C-zagdEOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validating(model, dataloader):\n",
        "\n",
        "    # capture validation time\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    # put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # track variables\n",
        "    total_valid_loss = 0\n",
        "\n",
        "    # evaluate data for one epoch\n",
        "    for batch in dataloader:\n",
        "\n",
        "        # Unpack this training batch from our dataloader:\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input tokens\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: target tokens\n",
        "        #   [3]: target attenion masks\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_input_mask = batch[1].cuda()\n",
        "        b_target_ids = batch[2].cuda()\n",
        "        b_target_mask = batch[3].cuda()\n",
        "\n",
        "        # tell pytorch not to bother calculating gradients\n",
        "        # as its only necessary for training\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids,\n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_target_ids,\n",
        "                            decoder_attention_mask=b_target_mask)\n",
        "\n",
        "            loss, prediction_scores = outputs[:2]\n",
        "\n",
        "            # sum the training loss over all batches for average loss at end\n",
        "            # loss is a tensor containing a single value\n",
        "            total_valid_loss += loss.item()\n",
        "\n",
        "    # calculate the average loss over all of the batches.\n",
        "    global avg_val_loss\n",
        "    avg_val_loss = total_valid_loss / len(dataloader)\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    valid_stats.append(\n",
        "        {\n",
        "            'Val Loss': avg_val_loss,\n",
        "            'Val PPL.': np.exp(avg_val_loss)\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # capture end validation time\n",
        "    training_time = format_time(time.time() - total_t0)\n",
        "\n",
        "    # print result summaries\n",
        "    print(\"\")\n",
        "    print(\"summary results\")\n",
        "    print(\"epoch | val loss | val ppl | val time\")\n",
        "    print(f\"{epoch+1:5d} | {avg_val_loss:.5f} | {np.exp(avg_val_loss):.3f} | {training_time:}\")\n",
        "\n",
        "    return valid_stats\n",
        "\n",
        "\n",
        "def testing(model, dataloader):\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Testing...\")\n",
        "\n",
        "    # measure training time\n",
        "    t0 = time.time()\n",
        "\n",
        "    # put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # track variables\n",
        "    total_test_loss = 0\n",
        "    total_test_acc = 0\n",
        "    total_test_f1 = 0\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    # evaluate data for one epoch\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        # progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader:\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input tokens\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: target tokens\n",
        "        #   [3]: target attenion masks\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_input_mask = batch[1].cuda()\n",
        "        b_target_ids = batch[2].cuda()\n",
        "        b_target_mask = batch[3].cuda()\n",
        "\n",
        "        # tell pytorch not to bother calculating gradients\n",
        "        # as its only necessary for training\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            outputs = model(input_ids=b_input_ids,\n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_target_ids,\n",
        "                            decoder_attention_mask=b_target_mask)\n",
        "\n",
        "            loss, prediction_scores = outputs[:2]\n",
        "\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                    input_ids=b_input_ids,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    max_length=3\n",
        "                    )\n",
        "\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in b_target_ids]\n",
        "\n",
        "            total_test_acc += accuracy_score(target, preds)\n",
        "            total_test_f1 += f1_score(preds, target,\n",
        "                                       average='weighted',\n",
        "                                       labels=np.unique(preds))\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "\n",
        "    # calculate the average loss over all of the batches.\n",
        "    avg_test_loss = total_test_loss / len(dataloader)\n",
        "\n",
        "    avg_test_acc = total_test_acc / len(test_dataloader)\n",
        "\n",
        "    avg_test_f1 = total_test_f1 / len(test_dataloader)\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    test_stats.append(\n",
        "        {\n",
        "            'Test Loss': avg_test_loss,\n",
        "            'Test PPL.': np.exp(avg_test_loss),\n",
        "            'Test Acc.': avg_test_acc,\n",
        "            'Test F1': avg_test_f1\n",
        "        }\n",
        "    )\n",
        "    global df2\n",
        "    temp_data = pd.DataFrame({'predicted': predictions, 'actual': actuals})\n",
        "    df2 = df2.append(temp_data)\n",
        "\n",
        "    return test_stats\n",
        "    \n",
        "\n",
        "# time function\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "ypTw76CVdNj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate model T5 transformer with a language modeling head on top\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small').cuda()  # to GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e73be978fff548fa89aefcf5cf8ceb6b",
            "beec321493904785b716c5223fea0abb",
            "70db1756527044afa0d2d995e787f6e9",
            "bcf0b1dfe41f41fc9b2393608e05d2cb",
            "3d724f1f79a94683b250d5ebc99789a0",
            "be0d017e26314437846105a8ac78a75a",
            "7ee1c067c3be4bd587a454048fc1df92",
            "7e3313f8255247e883eb7dd4ed1dd9c4",
            "d83cf857c8f044a8a51d60da4ff82ea8",
            "0fe08b3a8a3946c4ad84052d26f241d5",
            "c392ce4b65c04ddbb6af7cd8115a74f8"
          ]
        },
        "id": "1tiQ9u_WdkYf",
        "outputId": "f8151246-a458-4aab-8c48-fead6970c8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e73be978fff548fa89aefcf5cf8ceb6b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=24,\n",
        "                              # sampler=train_sampler,\n",
        "                              shuffle=False)\n",
        "\n",
        "valid_dataloader = DataLoader(val_dataset,\n",
        "                              batch_size=24,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                              batch_size=24,\n",
        "                              shuffle=True)\n",
        "\n",
        "\n",
        "# Adam w/ Weight Decay Fix\n",
        "# set to optimizer_grouped_parameters or model.parameters()\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 3e-5\n",
        "                  )\n",
        "\n",
        "# epochs\n",
        "epochs = 6\n",
        "\n",
        "# lr scheduler\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "# create gradient scaler for mixed precision\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvdok8dCdqsD",
        "outputId": "43d9aeea-4143-446f-f727-2d6c4cccf6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create training result storage\n",
        "training_stats = []\n",
        "valid_stats = []\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(epochs):\n",
        "    # train\n",
        "    train(model, train_dataloader, optimizer)\n",
        "    # validate\n",
        "    validating(model, valid_dataloader)\n",
        "    # check validation loss\n",
        "    if valid_stats[epoch]['Val Loss'] < best_valid_loss:\n",
        "        best_valid_loss = valid_stats[epoch]['Val Loss']\n",
        "        # save best model for use later\n",
        "        torch.save(model.state_dict(), 't5-classification.pt')  # torch save\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model\n",
        "        model_to_save.save_pretrained('./model_save/t5-classification/')  # transformers save\n",
        "        tokenizer.save_pretrained('./model_save/t5-classification/')  # transformers save"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT3275jsfGgM",
        "outputId": "67dbbf50-1bdf-49bc-cee6-d5dd3999ddca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 6 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    1 | 3.04583 | 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "\n",
            "summary results\n",
            "epoch | val loss | val ppl | val time\n",
            "    1 | 0.86599 | 2.377 | 0:00:01\n",
            "\n",
            "======== Epoch 2 / 6 ========\n",
            "Training...\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    2 | 0.79236 | 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "\n",
            "summary results\n",
            "epoch | val loss | val ppl | val time\n",
            "    2 | 0.20873 | 1.232 | 0:00:01\n",
            "\n",
            "======== Epoch 3 / 6 ========\n",
            "Training...\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    3 | 0.29711 | 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "\n",
            "summary results\n",
            "epoch | val loss | val ppl | val time\n",
            "    3 | 0.07883 | 1.082 | 0:00:01\n",
            "\n",
            "======== Epoch 4 / 6 ========\n",
            "Training...\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    4 | 0.18485 | 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "\n",
            "summary results\n",
            "epoch | val loss | val ppl | val time\n",
            "    4 | 0.05728 | 1.059 | 0:00:01\n",
            "\n",
            "======== Epoch 5 / 6 ========\n",
            "Training...\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    5 | 0.14208 | 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "\n",
            "summary results\n",
            "epoch | val loss | val ppl | val time\n",
            "    5 | 0.04496 | 1.046 | 0:00:01\n",
            "\n",
            "======== Epoch 6 / 6 ========\n",
            "Training...\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    6 | 0.13214 | 0:00:12\n",
            "\n",
            "Running Validation...\n",
            "\n",
            "summary results\n",
            "epoch | val loss | val ppl | val time\n",
            "    6 | 0.05264 | 1.054 | 0:00:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# organize results\n",
        "pd.set_option('precision', 3)\n",
        "df_train_stats = pd.DataFrame(data=training_stats)\n",
        "df_valid_stats = pd.DataFrame(data=valid_stats)\n",
        "df_stats = pd.concat([df_train_stats, df_valid_stats], axis=1)\n",
        "df_stats.insert(0, 'Epoch', range(1, len(df_stats)+1))\n",
        "df_stats = df_stats.set_index('Epoch')\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ZPd0WtP1fvrh",
        "outputId": "c79211cc-b03b-4812-e602-dc22813b9879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Train Loss  Val Loss  Val PPL.\n",
              "Epoch                                \n",
              "1           3.046     0.866     2.377\n",
              "2           0.792     0.209     1.232\n",
              "3           0.297     0.079     1.082\n",
              "4           0.185     0.057     1.059\n",
              "5           0.142     0.045     1.046\n",
              "6           0.132     0.053     1.054"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-378a6f3b-6aec-4e20-9062-70284ca2568a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Loss</th>\n",
              "      <th>Val Loss</th>\n",
              "      <th>Val PPL.</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.046</td>\n",
              "      <td>0.866</td>\n",
              "      <td>2.377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.792</td>\n",
              "      <td>0.209</td>\n",
              "      <td>1.232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.297</td>\n",
              "      <td>0.079</td>\n",
              "      <td>1.082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.185</td>\n",
              "      <td>0.057</td>\n",
              "      <td>1.059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.142</td>\n",
              "      <td>0.045</td>\n",
              "      <td>1.046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.132</td>\n",
              "      <td>0.053</td>\n",
              "      <td>1.054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-378a6f3b-6aec-4e20-9062-70284ca2568a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-378a6f3b-6aec-4e20-9062-70284ca2568a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-378a6f3b-6aec-4e20-9062-70284ca2568a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "df2 = pd.DataFrame({'predicted': [], 'actual': []})\n",
        "test_stats = []\n",
        "model.load_state_dict(torch.load('t5-classification.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcM_qt4zf7Mc",
        "outputId": "e21271ba-0a61-49b1-9a8d-e2c5d7857a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing(model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1peLw8H-gbs2",
        "outputId": "4162b702-69bb-46d2-d9b6-e0e6a4462dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Testing...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Test Loss': 0.04188517183065414,\n",
              "  'Test PPL.': 1.0427747319622311,\n",
              "  'Test Acc.': 0.9666666666666668,\n",
              "  'Test F1': 0.9653385503385504}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_stats = pd.DataFrame(data=test_stats)\n",
        "print(df_test_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu7-uGiCgf34",
        "outputId": "42cb80be-6fbd-4825-aa37-17c7d2571aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Test Loss  Test PPL.  Test Acc.  Test F1\n",
            "0      0.042      1.043      0.967    0.965\n"
          ]
        }
      ]
    }
  ]
}